{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caklem/2141720236-mobile-2023-2/blob/main/Quiz2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "fLV1Z5_Za3Ni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUhYpAeEarrV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "N95oXMaTcnMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST"
      ],
      "metadata": {
        "id": "dT8TY908cpCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "OIZx2pkUcfDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "3GLkzBi6czj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape data\n",
        "(train_data.shape, test_data.shape)"
      ],
      "metadata": {
        "id": "oVQTyPgAc5Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape labels\n",
        "(train_labels.shape, test_labels.shape)"
      ],
      "metadata": {
        "id": "grUhLPwJc-un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check each data shape --> should be 28*28\n",
        "train_data[0].shape"
      ],
      "metadata": {
        "id": "AwsTEu6xdNKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the label\n",
        "train_labels.shape"
      ],
      "metadata": {
        "id": "KHZesdnBdXKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Train and Test Data"
      ],
      "metadata": {
        "id": "SYz8IjnOdfsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_data = np.vstack([train_data, test_data])\n",
        "digits_labels = np.hstack([train_labels, test_labels])"
      ],
      "metadata": {
        "id": "yacSZjdPdbhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data shape\n",
        "digits_data.shape"
      ],
      "metadata": {
        "id": "oRBvQNVUeHZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check label shape\n",
        "digits_labels.shape"
      ],
      "metadata": {
        "id": "MZbUcu0MeLSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly checking the data\n",
        "idx = np.random.randint(0, digits_data.shape[0])\n",
        "plt.imshow(digits_data[idx], cmap='gray')\n",
        "plt.title('Class: ' + str(digits_labels[idx]))"
      ],
      "metadata": {
        "id": "uqaiC0pGePF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data distribution\n",
        "df_labels = pd.DataFrame(digits_labels, columns=['Labels'])\n",
        "sns.countplot(df_labels, x='Labels')"
      ],
      "metadata": {
        "id": "FrLWteorevqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Kaggle A-Z"
      ],
      "metadata": {
        "id": "uqeJT2ytogB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://iaexpert.academy/arquivos/alfabeto_A-Z.zip"
      ],
      "metadata": {
        "id": "tQ95CkdfjO7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract zip file\n",
        "zip_object = zipfile.ZipFile(file = 'alfabeto_A-Z.zip', mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "metadata": {
        "id": "TobpFNSsojcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_az = pd.read_csv('A_Z Handwritten Data.csv').astype('float32')\n",
        "dataset_az"
      ],
      "metadata": {
        "id": "ScBURU_4o5bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get pixel data only\n",
        "alphabet_data = dataset_az.drop('0', axis=1)\n",
        "# Get labels only\n",
        "alphabet_labels = dataset_az['0']"
      ],
      "metadata": {
        "id": "dK6pP0b-o81T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape data\n",
        "alphabet_data.shape, alphabet_labels.shape"
      ],
      "metadata": {
        "id": "NllEoaiLpZhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape labels\n",
        "alphabet_labels.shape"
      ],
      "metadata": {
        "id": "UvE88zSkpe5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape pixel data to 28*28\n",
        "alphabet_data = np.reshape(alphabet_data.values, (alphabet_data.shape[0], 28, 28))\n",
        "# Check the result by its shape\n",
        "alphabet_data.shape"
      ],
      "metadata": {
        "id": "9xps-5kjpio_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly checking A-Z dataset\n",
        "index = np.random.randint(0, alphabet_data.shape[0])\n",
        "plt.imshow(alphabet_data[index], cmap = 'gray')\n",
        "plt.title('Class: ' + str(alphabet_labels[index]));"
      ],
      "metadata": {
        "id": "tDTBbWSoqloX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data distribution\n",
        "df_az_labels = pd.DataFrame({\n",
        "    'Labels': alphabet_labels.values\n",
        "})\n",
        "sns.countplot(df_az_labels, x='Labels')"
      ],
      "metadata": {
        "id": "72frSp_uqrjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Dataset (MNIST + Kaggel A-Z)"
      ],
      "metadata": {
        "id": "YZf14K79sdEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique value from digits_labels\n",
        "np.unique(digits_labels)"
      ],
      "metadata": {
        "id": "9voZzZ8Krqk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique value from alphabet_labels\n",
        "np.unique(alphabet_labels)"
      ],
      "metadata": {
        "id": "9ZzBJFKxs1AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We already know that digits labels containt labels from 0-9 (10 labels)\n",
        "# We also know that alphabet labels start from 0-25 which represent A-Z\n",
        "# If we want to combine them, the A-Z labels should continuing the digits label\n",
        "\n",
        "alphabet_labels += 10"
      ],
      "metadata": {
        "id": "dM0GV8lIsnzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check alphabet labels again\n",
        "np.unique(alphabet_labels)"
      ],
      "metadata": {
        "id": "42YKtJB-tQC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both of them\n",
        "data = np.vstack([alphabet_data, digits_data])\n",
        "labels = np.hstack([alphabet_labels, digits_labels])"
      ],
      "metadata": {
        "id": "1ydXPXiItVVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape\n",
        "data.shape, labels.shape"
      ],
      "metadata": {
        "id": "-vYLoXFjuLz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check labels\n",
        "np.unique(labels)"
      ],
      "metadata": {
        "id": "biyM6WueuRG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to float32\n",
        "data = np.array(data, dtype = 'float32')"
      ],
      "metadata": {
        "id": "vuEt24lhuVfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since Convolutional need 3d data (including depth)\n",
        "# and our images only in 2d data (because in grayscale format)\n",
        "# we need to add \"the depth\" to the data\n",
        "data = np.expand_dims(data, axis=-1)\n",
        "\n",
        "# check shape\n",
        "data.shape"
      ],
      "metadata": {
        "id": "UC6Vhz59ucdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "xF71lXtSu3YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "data /= 255.0"
      ],
      "metadata": {
        "id": "kFjjP_JLuzbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check range value of data\n",
        "data[0].min(), data[0].max()"
      ],
      "metadata": {
        "id": "zztStKZOu-Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enconde the labels\n",
        "# LabelBinarizer similar with OneHotEncoder\n",
        "le = LabelBinarizer()\n",
        "labels = le.fit_transform(labels)"
      ],
      "metadata": {
        "id": "s2C5yKEGu7vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check labels shape\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "Bo1M5YEmvg5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data with label binarizer's label\n",
        "plt.imshow(data[30000].reshape(28,28), cmap='gray')\n",
        "plt.title(str(labels[0]))"
      ],
      "metadata": {
        "id": "jCL5ipbsvjpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since our data is not balance, we will handle it by giving weight for 'small' data\n",
        "\n",
        "# Check number of data for each labels first\n",
        "classes_total = labels.sum(axis = 0)\n",
        "classes_total"
      ],
      "metadata": {
        "id": "njDbZXKzvsx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the biggest value of data\n",
        "classes_total.max()"
      ],
      "metadata": {
        "id": "R1hHYtGLv_ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a weight for each data\n",
        "classes_weights = {}\n",
        "for i in range(0, len(classes_total)):\n",
        "  #print(i)\n",
        "  classes_weights[i] = classes_total.max() / classes_total[i]\n",
        "\n",
        "# Check the weight for each data\n",
        "classes_weights"
      ],
      "metadata": {
        "id": "7TJFrxS2wFTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data to Train and Test"
      ],
      "metadata": {
        "id": "VtDS1O6JwSQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, random_state = 1, stratify = labels)"
      ],
      "metadata": {
        "id": "rV62GJySwM2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Data Augmentation"
      ],
      "metadata": {
        "id": "q7Hs5GwGxw4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Xn1jiVn9x2Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = ImageDataGenerator(rotation_range = 10, zoom_range=0.05, width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1, horizontal_flip = False)"
      ],
      "metadata": {
        "id": "su41P3box6Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build CNN Model"
      ],
      "metadata": {
        "id": "GYwIT1TZw8SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "nvQ2Ly4zwX8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the network\n",
        "network = Sequential()\n",
        "\n",
        "network.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
        "network.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "network.add(Conv2D(filters = 64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "network.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "network.add(Conv2D(filters = 128, kernel_size=(3,3), activation='relu', padding='valid'))\n",
        "network.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "network.add(Flatten())\n",
        "\n",
        "network.add(Dense(64, activation = 'relu'))\n",
        "network.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "network.add(Dense(36, activation='softmax'))\n",
        "\n",
        "network.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "icRreUChxAwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check network summary\n",
        "network.summary()"
      ],
      "metadata": {
        "id": "nAuCYbRWxIKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create actual labels\n",
        "name_labels = '0123456789'\n",
        "name_labels += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "name_labels = [l for l in name_labels]\n",
        "\n",
        "# Check actual label\n",
        "print(name_labels)"
      ],
      "metadata": {
        "id": "o7Vc4ly2xMhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "DH7hSW38xX6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model name, epoch, and batch size\n",
        "file_model = 'custom_ocr.model'\n",
        "epochs = 20\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "rNQ_-PY7xVRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup checkpoint\n",
        "checkpointer = ModelCheckpoint(file_model, monitor = 'val_loss', verbose = 1, save_best_only=True)"
      ],
      "metadata": {
        "id": "F8Orj5UQxdtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = network.fit(augmentation.flow(X_train, y_train, batch_size=batch_size),\n",
        "                      validation_data = (X_test, y_test),\n",
        "                      steps_per_epoch = len(X_train) // batch_size, epochs=epochs,\n",
        "                      class_weight = classes_weights, verbose=1, callbacks=[checkpointer])"
      ],
      "metadata": {
        "id": "enFAwiaxxkgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "bM4mGoWL6jxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a Single Prediction"
      ],
      "metadata": {
        "id": "ig0TiV6N7V29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5pbMkmvg7V0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "predictions = network.predict(X_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "WDJUSW-l6lEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check prediction for data-0\n",
        "# You will get the probability for each label\n",
        "# The highest one is the prediction\n",
        "predictions[1]"
      ],
      "metadata": {
        "id": "tQ5Ta4b96pEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the actual prediction -> highest probability\n",
        "np.argmax(predictions[1])"
      ],
      "metadata": {
        "id": "9THTrYAH64g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check label for 24\n",
        "name_labels[18]"
      ],
      "metadata": {
        "id": "pG6n2eTI6-Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check y_test label for 0\n",
        "y_test[1]"
      ],
      "metadata": {
        "id": "chDSvyYq7Bxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the highest value\n",
        "np.argmax(y_test[1])"
      ],
      "metadata": {
        "id": "BpoE99Us7KpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the label of y_test 0\n",
        "name_labels[np.argmax(y_test[18])]"
      ],
      "metadata": {
        "id": "KjJRX1lC7Ppw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make an Evaluation on Test Data"
      ],
      "metadata": {
        "id": "_xFS3-cs7a0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "network.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "t-rko8WP7TYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Classification Report\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names = name_labels))"
      ],
      "metadata": {
        "id": "VkQtgoCq7gx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize loss value for each epoch\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "mIETfqMu7nv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also check the another metrics\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "mNUP1QP17vas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model performance by validation accuracy\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "VwEZzjEa716s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save The Model"
      ],
      "metadata": {
        "id": "D0rviDyl79Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The result will show in colab directory\n",
        "network.save('network', save_format= 'h5')"
      ],
      "metadata": {
        "id": "QZ4ftlmq76nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on Real Image"
      ],
      "metadata": {
        "id": "A3EWZVrz0YDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "1wUedJB-0Z_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved network\n",
        "load_network = load_model('network')"
      ],
      "metadata": {
        "id": "D6E24QOm0hiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check summary\n",
        "load_network.summary()"
      ],
      "metadata": {
        "id": "0cB7lmOc0nlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('b_small.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "hbnaTxZK07JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape\n",
        "img.shape"
      ],
      "metadata": {
        "id": "EfDOYN6D1OZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to gray\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# check shape\n",
        "gray_img.shape"
      ],
      "metadata": {
        "id": "7e6w1zaL1RW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process\n",
        "# Binary Threshold and Otsu\n",
        "value, thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "cv2_imshow(thresh)\n",
        "\n",
        "# print threshold value\n",
        "print(value)"
      ],
      "metadata": {
        "id": "9_al0IF01c3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image in order to match network input shape -> 28*28\n",
        "img_resize = cv2.resize(gray_img, (28,28))\n",
        "cv2_imshow(img_resize)"
      ],
      "metadata": {
        "id": "dmjHswqd1wB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to float 32\n",
        "# and extend the dimension since network input shape is 28*28*1\n",
        "img_input = img_resize.astype('float32') / 255 # also perform normalization\n",
        "img_input = np.expand_dims(img_input, axis=-1) # insert depth\n",
        "\n",
        "# check shape\n",
        "img_input.shape"
      ],
      "metadata": {
        "id": "bZStKgUl2Kk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add \"amount of data\" as dimension\n",
        "img_input = np.reshape(img_input, (1,28,28,1))\n",
        "img_input.shape"
      ],
      "metadata": {
        "id": "7Xs7JwKj2lxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a predition\n",
        "prediction = load_network.predict(img_input)\n",
        "pred_label = np.argmax(prediction) # predict actual label\n",
        "pred_label"
      ],
      "metadata": {
        "id": "fZLWIWLs2yuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check label for 6\n",
        "name_labels[6]"
      ],
      "metadata": {
        "id": "72Pl04hq3WNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2EmYPAN3hrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}